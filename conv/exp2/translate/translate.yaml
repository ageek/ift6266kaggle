!obj:transformer.TransformationPipeline { 
            input_space: !obj:pylearn2.space.Conv2DSpace {
                shape: [48, 48],
                num_channels: 1,
                axes: ['b', 0, 1, 'c'],
            },
            transformations: [ 

            # Translates the image in x and y coordinates 
            # translation is done in float and pixels values are interpolated
            !obj:transformer.Translation {
                p: %(p)f,               # Probability that a translation is applied
                random_fct: 'normal',   # Random function from numpy to sample translation in
                                        # x and y coordinates
                fct_settings: {         # Settings for the random function
                    loc: 0.0,           # See numpy documentation for more details
                    scale: %(scale)f
                },
                min: None,              # Minimum/Maximum value accepted, resampled otherwise
                max: None               # until it finds a valid value or until 50 tries.
                                        # Be cautious when you set min/max values regarding 
                                        # what the random_fct can generate. It is computationnaly
                                        # expensive to resample too often, so an Exception is raised
                                        # if 50 tries fail and the trainning crash.
            }
        ] 
}
